
@article{mlgp,
	title = {A {Fast} and {High} {Quality} {Multilevel} {Scheme} for {Partitioning} {Irregular} {Graphs}},
	volume = {20},
	issn = {1064-8275},
	abstract = {Recently, a number of researchers have investigated a class of graph partitioning algorithms that reduce the size of the graph by collapsing vertices and edges, partition the smaller graph, and then uncoarsen it to construct a partition for the original graph [Bui and Jones, Proc. of the 6th SIAM Conference on Parallel Processing for Scientific Computing, 1993, 445–452; Hendrickson and Leland, A Multilevel Algorithm for Partitioning Graphs, Tech. report SAND 93-1301, Sandia National Laboratories, Albuquerque, NM, 1993]. From the early work it was clear that multilevel techniques held great promise; however, it was not known if they can be made to consistently produce high quality partitions for graphs arising in a wide range of application domains. We investigate the effectiveness of many different choices for all three phases: coarsening, partition of the coarsest graph, and refinement. In particular, we present a new coarsening heuristic (called heavy-edge heuristic) for which the size of the partition of the coarse graph is within a small factor of the size of the final partition obtained after multilevel refinement. We also present a much faster variation of the Kernighan–Lin (KL) algorithm for refining during uncoarsening. We test our scheme on a large number of graphs arising in various domains including finite element methods, linear programming, VLSI, and transportation. Our experiments show that our scheme produces partitions that are consistently better than those produced by spectral partitioning schemes in substantially smaller time. Also, when our scheme is used to compute fill-reducing orderings for sparse matrices, it produces orderings that have substantially smaller fill than the widely used multiple minimum degree algorithm.},
	number = {1},
	journal = {SIAM J. Sci. Comput.},
	author = {Karypis, George and Kumar, Vipin},
	month = dec,
	year = {1998},
	note = {Place: USA
Publisher: Society for Industrial and Applied Mathematics},
	keywords = {fill-reducing orderings, finite element computations, graph partitioning, parallel computations},
	pages = {359--392},
	file = {Karypis and Kumar - 1998 - A Fast and High Quality Multilevel Scheme for Part.pdf:/home/iris/Zotero/storage/2CMFE39G/Karypis and Kumar - 1998 - A Fast and High Quality Multilevel Scheme for Part.pdf:application/pdf},
}

@article{riondato,
	title = {Fast approximation of betweenness centrality through sampling},
	volume = {30},
	doi = {10.1007/s10618-015-0423-0},
	number = {2},
	journal = {Data Mining and Knowledge Discovery},
	author = {Riondato, Matteo and Kornaropoulos, Evgenios M.},
	year = {2015},
	pages = {438--475},
	annote = {Used by KADABRA for c},
	file = {Full Text:/home/iris/Zotero/storage/RPWCDBQW/Riondato and Kornaropoulos - 2015 - Fast approximation of betweenness centrality throu.pdf:application/pdf},
}

@article{loffler,
	title = {Shape {Fitting} on {Point} {Sets} with {Probability} {Distributions}},
	doi = {10.1007/978-3-642-04128-0_29},
	journal = {Lecture Notes in Computer Science Algorithms - ESA 2009},
	author = {Löffler, Maarten and Phillips, Jeff M.},
	year = {2009},
	pages = {313--324},
	annote = {Estimates C},
	file = {Full Text:/home/iris/Zotero/storage/CB3NB2XH/Löffler and Phillips - 2009 - Shape Fitting on Point Sets with Probability Distr.pdf:application/pdf},
}

@article{brandescomplexity,
	title = {Into the {Square} - {On} the {Complexity} of {Quadratic}-{Time} {Solvable} {Problems}},
	url = {http://arxiv.org/abs/1407.4972},
	abstract = {This paper will analyze several quadratic-time solvable problems, and will classify them into two classes: problems that are solvable in truly subquadratic time (that is, in time \$O(nˆ\{2-{\textbackslash}textbackslashepsilon\})\$ for some \${\textbackslash}textbackslashepsilon{\textbackslash}textgreater0\$) and problems that are not, unless the well known Strong Exponential Time Hypothesis (SETH) is false. In particular, we will prove that some quadratic-time solvable problems are indeed easier than expected. We will provide an algorithm that computes the transitive closure of a directed graph in time \$O(mnˆ\{{\textbackslash}textbackslashfrac\{{\textbackslash}textbackslashomega+1\}\{4\}\})\$, where \$m\$ denotes the number of edges in the transitive closure and \${\textbackslash}textbackslashomega\$ is the exponent for matrix multiplication. As a side effect, we will prove that our algorithm runs in time \$O(nˆ\{{\textbackslash}textbackslashfrac\{5\}\{3\}\})\$ if the transitive closure is sparse. The same time bounds hold if we want to check whether a graph is transitive, by replacing m with the number of edges in the graph itself. As far as we know, this is the fastest algorithm for sparse transitive digraph recognition. Finally, we will apply our algorithm to the comparability graph recognition problem (dating back to 1941), obtaining the first truly subquadratic algorithm. The second part of the paper deals with hardness results. Starting from an artificial quadratic-time solvable variation of the k-SAT problem, we will construct a graph of Karp reductions, proving that a truly subquadratic-time algorithm for any of the problems in the graph falsifies SETH. The analyzed problems are the following: computing the subset graph, finding dominating sets, computing the betweenness centrality of a vertex, computing the minimum closeness centrality, and computing the hyperbolicity of a pair of vertices. We will also be able to include in our framework three proofs already appeared in the literature, concerning the graph diameter computation, local alignment of strings and orthogonality of vectors.},
	urldate = {2021-02-13},
	journal = {arXiv:1407.4972 [cs]},
	author = {Borassi, Michele and Crescenzi, Pierluigi and Habib, Michel},
	month = jul,
	year = {2014},
	keywords = {Computer Science - Computational Complexity},
	annote = {arXiv: 1407.4972},
	annote = {Shows hardness of Betweenness Centrality},
	file = {Full Text:/home/iris/Zotero/storage/ZT3CZSZP/Borassi et al. - 2014 - Into the Square - On the Complexity of Quadratic-T.pdf:application/pdf},
}

@article{freeman,
	title = {A {Set} of {Measures} of {Centrality} {Based} on {Betweenness}},
	volume = {40},
	issn = {00380431},
	url = {http://www.jstor.org/stable/3033543},
	abstract = {A Family of new measures of point and graph centrality based on early intuitions of Bavelas (1948) is introduced. These measures define centrality in terms of the degree to which a point falls on the shortest path between others and therefore has a potential for control of communication. They may be used to index centrality in any large or small network of symmetrical relations, whether connected or unconnected.},
	number = {1},
	journal = {Sociometry},
	author = {Freeman, Linton C.},
	year = {1977},
	note = {Publisher: [American Sociological Association, Sage Publications, Inc.]},
	pages = {35--41},
	file = {Freeman - 1977 - A Set of Measures of Centrality Based on Betweenne.pdf:/home/iris/Zotero/storage/VWH8UTST/Freeman - 1977 - A Set of Measures of Centrality Based on Betweenne.pdf:application/pdf},
}

@book{string,
	title = {Welcome to {STRING}},
	url = {https://string-db.org/},
	author = {Bork, Peer and Jensen, Lars Juhl and von Mering, Christian},
}

@article{bio,
	title = {Network {Analysis} of {Protein} {Structures} {Identifies} {Functional} {Residues}},
	volume = {344},
	issn = {0022-2836},
	url = {http://www.sciencedirect.com/science/article/pii/S0022283604013592},
	doi = {https://doi.org/10.1016/j.jmb.2004.10.055},
	abstract = {Identifying active site residues strictly from protein three-dimensional structure is a difficult task, especially for proteins that have few or no homologues. We transformed protein structures into residue interaction graphs (RIGs), where amino acid residues are graph nodes and their interactions with each other are the graph edges. We found that active site, ligand-binding and evolutionary conserved residues, typically have high closeness values. Residues with high closeness values interact directly or by a few intermediates with all other residues of the protein. Combining closeness and surface accessibility identified active site residues in 70\% of 178 representative structures. Detailed structural analysis of specific enzymes also located other types of functional residues. These include the substrate binding sites of acetylcholinesterases and subtilisin, and the regions whose structural changes activate MAP kinase and glycogen phosphorylase. Our approach uses single protein structures, and does not rely on sequence conservation, comparison to other similar structures or any prior knowledge. Residue closeness is distinct from various sequence and structure measures and can thus complement them in identifying key protein residues. Closeness integrates the effect of the entire protein on single residues. Such natural structural design may be evolutionary maintained to preserve interaction redundancy and contribute to optimal setting of functional sites.},
	number = {4},
	journal = {Journal of Molecular Biology},
	author = {Amitai, Gil and Shemesh, Arye and Sitbon, Einat and Shklar, Maxim and Netanely, Dvir and Venger, Ilya and Pietrokovski, Shmuel},
	year = {2004},
	keywords = {closeness degree, network analysis, ORFans, protein active sites identification, protein structure analysis},
	pages = {1135 -- 1146},
	annote = {To show graphs useful for bio},
}

@article{supply,
	title = {Mapping supply chain risk by network analysis of product platforms},
	volume = {10},
	issn = {2214-9937},
	url = {http://www.sciencedirect.com/science/article/pii/S2214993716300318},
	doi = {https://doi.org/10.1016/j.susmat.2016.10.002},
	abstract = {Modern technology makes use of a variety of materials to allow for its proper functioning. To explore in detail the relationships connecting materials to the products that require them, we map supply chains for five product platforms (a cadmium telluride solar cell, a germanium solar cell, a turbine blade, a lead acid battery, and a hard drive (HD) magnet) using a data ontology that specifies the supply chain actors (nodes) and linkages (e.g., material exchange and contractual relationships) among them. We then propose a set of network indicators (product complexity, producer diversity, supply chain length, and potential bottlenecks) to assess the situation for each platform in the overall supply chain networks. Among the results of interest are the following: (1) the turbine blade displays a high product complexity, defined by the material linkages to the platform; (2) the germanium solar cell is produced by only a few manufacturers globally and requires more physical transformation steps than do the other project platforms; (3) including production quantity and sourcing countries in the assessment shows that a large portion of nodes of the supply chain of the hard-drive magnet are located in potentially unreliable countries. We conclude by discussing how the network analysis of supply chains could be combined with criticality and scenario analyses of abiotic raw materials to comprise a comprehensive picture of product platform risk.},
	journal = {Sustainable Materials and Technologies},
	author = {Nuss, Philip and Graedel, T. E. and Alonso, Elisa and Carroll, Adam},
	year = {2016},
	keywords = {Metals criticality, Product platforms, Social network analysis, Supply chain risk assessment, Sustainable resource management},
	pages = {14 -- 22},
	annote = {To show graphs useful},
}

@article{social,
	title = {Social network analysis: a powerful strategy, also for the information sciences},
	volume = {28},
	url = {https://doi.org/10.1177/016555150202800601},
	doi = {10.1177/016555150202800601},
	abstract = {Social network analysis (SNA) is not a formal theory in sociology but rather a strategy for investigating social structures. As it is an idea that can be applied in many fields, we study, in particular, its influence in the information sciences. Information scientists study publication, citation and co-citation networks, collaboration structures and other forms of social interaction networks. Moreover, the Internet represents a social network of an unprecedented scale. In all these studies social network analysis can successfully be applied. SNA is further related to recent theories concerning the free market economy, geography and transport networks. The growth of SNA is documented and a co-author network of SNA is drawn. Centrality measures of the SNA network are calculated.},
	number = {6},
	journal = {Journal of Information Science},
	author = {Otte, Evelien and Rousseau, Ronald},
	year = {2002},
	note = {\_eprint: https://doi.org/10.1177/016555150202800601},
	pages = {441--453},
	annote = {To show graphs useful for sociology
 },
	file = {Full Text:/home/iris/Zotero/storage/73X7WFLP/Otte and Rousseau - 2002 - Social network analysis a powerful strategy, also.pdf:application/pdf},
}

@article{disease,
	title = {Network {Based} {Model} of {Infectious} {Disease} {Transmission} in {Macroalgae}},
	volume = {19},
	doi = {10.5013/IJSSST.a.19.05.11},
	journal = {International Journal of Simulation: Systems, Science and Technology},
	author = {Pipatsart, Navavat and Modchang, Charin and Triampo, Wannapong and Amornsamankul, Somkid},
	year = {2018},
	pages = {11.1--11.8},
	annote = {To show graphs useful for pathology},
}

@article{brandes,
	title = {A faster algorithm for betweenness centrality},
	volume = {25},
	url = {https://doi.org/10.1080/0022250X.2001.9990249},
	doi = {10.1080/0022250X.2001.9990249},
	number = {2},
	journal = {The Journal of Mathematical Sociology},
	author = {Brandes, Ulrik},
	year = {2001},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/0022250X.2001.9990249},
	pages = {163--177},
	file = {Full Text:/home/iris/Zotero/storage/9KISCDUC/Brandes - 2001 - A faster algorithm for betweenness centrality.pdf:application/pdf},
}

@article{brandes2007,
	title = {{CENTRALITY} {ESTIMATION} {IN} {LARGE} {NETWORKS}},
	volume = {17},
	url = {https://doi.org/10.1142/S0218127407018403},
	doi = {10.1142/S0218127407018403},
	abstract = {Centrality indices are an essential concept in network analysis. For those based on shortest-path distances the computation is at least quadratic in the number of nodes, since it usually involves solving the single-source shortest-paths (SSSP) problem from every node. Therefore, exact computation is infeasible for many large networks of interest today. Centrality scores can be estimated, however, from a limited number of SSSP computations. We present results from an experimental study of the quality of such estimates under various selection strategies for the source vertices.},
	number = {07},
	journal = {International Journal of Bifurcation and Chaos},
	author = {Brandes, Ulrik and Pich, Christian},
	year = {2007},
	note = {\_eprint: https://doi.org/10.1142/S0218127407018403},
	pages = {2303--2318},
	file = {Submitted Version:/home/iris/Zotero/storage/BCWFT67E/Brandes and Pich - 2007 - CENTRALITY ESTIMATION IN LARGE NETWORKS.pdf:application/pdf},
}

@book{erdos,
	title = {A {Divide}-and-{Conquer} {Algorithm} for {Betweenness} {Centrality}},
	author = {Erdos, Dora and Ishakian, Vatche and Bestavros, Azer and Terzi, Evimaria},
	year = {2015},
	note = {\_eprint: 1406.4173},
	file = {published-Erdos et al. - 2015 - A Divide-and-Conquer Algorithm for Betweenness Cen.pdf:/home/iris/Zotero/storage/XAKZ9NSD/published-Erdos et al. - 2015 - A Divide-and-Conquer Algorithm for Betweenness Cen.pdf:application/pdf;archivex-Erdos et al. - 2015 - A Divide-and-Conquer Algorithm for Betweenness Cen.pdf:/home/iris/Zotero/storage/4INBNJ73/archivex-Erdos et al. - 2015 - A Divide-and-Conquer Algorithm for Betweenness Cen.pdf:application/pdf},
}

@inproceedings{bader,
	address = {Berlin, Heidelberg},
	title = {Approximating {Betweenness} {Centrality}},
	isbn = {978-3-540-77004-6},
	abstract = {Betweenness is a centrality measure based on shortest paths, widely used in complex network analysis. It is computationally-expensive to exactly determine betweenness; currently the fastest-known algorithm by Brandes requires O(nm) time for unweighted graphs and O(nmþinspace+þinspacen2logn) time for weighted graphs, where n is the number of vertices and m is the number of edges in the network. These are also the worst-case time bounds for computing the betweenness score of a single vertex. In this paper, we present a novel approximation algorithm for computing betweenness centrality of a given vertex, for both weighted and unweighted graphs. Our approximation algorithm is based on an adaptive sampling technique that significantly reduces the number of single-source shortest path computations for vertices with high centrality. We conduct an extensive experimental study on real-world graph instances, and observe that our random sampling algorithm gives very good betweenness approximations for biological networks, road networks and web crawls.},
	booktitle = {Algorithms and {Models} for the {Web}-{Graph}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bader, David A. and Kintali, Shiva and Madduri, Kamesh and Mihail, Milena},
	editor = {Bonato, Anthony and Chung, Fan R. K.},
	year = {2007},
	pages = {124--137},
	file = {Bader et al. - 2007 - Approximating Betweenness Centrality.pdf:/home/iris/Zotero/storage/GLZ8D5YC/Bader et al. - 2007 - Approximating Betweenness Centrality.pdf:application/pdf},
}

@article{borassi,
	title = {{KADABRA} is an {ADaptive} {Algorithm} for {Betweenness} via {Random} {Approximation}},
	volume = {abs/1604.08553},
	url = {http://arxiv.org/abs/1604.08553},
	journal = {CoRR},
	author = {Borassi, Michele and Natale, Emanuele},
	year = {2016},
	note = {\_eprint: 1604.08553},
	file = {Full Text:/home/iris/Zotero/storage/WJUVLZDS/Borassi and Natale - 2016 - KADABRA is an ADaptive Algorithm for Betweenness v.pdf:application/pdf},
}

@inproceedings{geisberger,
	address = {USA},
	title = {Better {Approximation} of {Betweenness} {Centrality}},
	abstract = {Estimating the importance or centrality of the nodes in large networks has recently attracted increased interest. Betweenness is one of the most important centrality indices, which basically counts the number of shortest paths going through a node. Betweenness has been used in diverse applications, e.g., social network analysis or route planning. Since exact computation is prohibitive for large networks, approximation algorithms are important. In this paper, we propose a framework for unbiased approximation of betweenness that generalizes a previous approach by Brandes. Our best new schemes yield significantly better approximation than before for many real world inputs. In particular, we also get good approximations for the betweenness of unimportant nodes.},
	booktitle = {Proceedings of the {Meeting} on {Algorithm} {Engineering} \& {Expermiments}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Geisberger, Robert and Sanders, Peter and Schultes, Dominik},
	year = {2008},
	note = {event-place: San Francisco, California},
	pages = {90--100},
}

@book{snap,
	title = {{SNAP} {Datasets}: {Stanford} {Large} {Network} {Dataset} {Collection}},
	url = {http://snap.stanford.edu/data},
	author = {Leskovec, Jure and Krevl, Andrej},
	month = jun,
	year = {2014},
}

@article{comparesmall,
	title = {Comparing the speed and accuracy of approaches to betweenness centrality approximation},
	volume = {6},
	issn = {2197-4314},
	url = {https://doi.org/10.1186/s40649-019-0062-5},
	doi = {10.1186/s40649-019-0062-5},
	abstract = {Many algorithms require doing a large number of betweenness centrality calculations quickly, and accommodating this need is an active open research area. There are many different ideas and approaches to speeding up these calculations, and it is difficult to know which approach will work best in practical situations.},
	number = {1},
	journal = {Computational Social Networks},
	author = {Matta, John and Ercal, Gunes and Sinha, Koushik},
	month = feb,
	year = {2019},
	pages = {2},
	file = {Full Text:/home/iris/Zotero/storage/MIKWUSTJ/Matta et al. - 2019 - Comparing the speed and accuracy of approaches to .pdf:application/pdf},
}

@inproceedings{comparebig,
	address = {New York, NY, USA},
	series = {{SSDBM} '17},
	title = {A {Benchmark} for {Betweenness} {Centrality} {Approximation} {Algorithms} on {Large} {Graphs}},
	isbn = {978-1-4503-5282-6},
	url = {https://doi.org/10.1145/3085504.3085510},
	doi = {10.1145/3085504.3085510},
	abstract = {Betweenness centrality quantifies the importance of graph nodes in a variety of applications including social, biological and communication networks. Its computation is very costly for large graphs; therefore, many approximate methods have been proposed. Given the lack of a golden standard, the accuracy of most approximate methods is evaluated on tiny graphs and is not guaranteed to be representative of realistic datasets that are orders of magnitude larger. In this paper, we develop BeBeCA, a benchmark for betweenness centrality approximation methods on large graphs. Specifically: (i) We generate a golden standard by deploying a parallel implementation of Brandes algorithm using 96,000 CPU cores on a supercomputer to compute exact betweenness centrality values for several large graphs with up to 126M edges. (ii) We propose an evaluation methodology to assess various aspects of approximation accuracy, such as average error and quality of node ranking. (iii) We survey a large number of existing approximation methods and compare their performance and accuracy using our benchmark. (iv) We publicly share our benchmark, which includes the golden standard exact betweenness centrality values together with the scripts that implement our evaluation methodology; for researchers to compare their own algorithms and practitioners to select the appropriate algorithm for their application and data.},
	booktitle = {Proceedings of the 29th {International} {Conference} on {Scientific} and {Statistical} {Database} {Management}},
	publisher = {Association for Computing Machinery},
	author = {AlGhamdi, Ziyad and Jamour, Fuad and Skiadopoulos, Spiros and Kalnis, Panos},
	year = {2017},
	note = {event-place: Chicago, IL, USA},
	keywords = {Approximation Algorithms, Betweenness Centrality, Experimental Evaluation, Social Networks},
	file = {Full Text:/home/iris/Zotero/storage/UMASSW7R/AlGhamdi et al. - 2017 - A Benchmark for Betweenness Centrality Approximati.pdf:application/pdf},
}

@book{repository,
	title = {Network {Data} {Repository}: {The} {First} {Interactive} {Network} {Data} {Repository}},
	url = {http://networkrepository.com/},
	author = {Rossi, Ryan A. and Ahmed, Nesreen K.},
	year = {2020},
	note = {Publication Title: Network Repository},
}

@article{floyd,
	title = {Algorithm 97–{Shortest} {Path}},
	volume = {5},
	language = {fr},
	journal = {Communications of ACM},
	author = {Floyd, Robert W.},
	year = {1962},
	pages = {345},
	file = {FLOYD - 1962 - Algorithm 97–Shortest Path.pdf:/home/iris/Zotero/storage/Z2GZ6Q8A/FLOYD - 1962 - Algorithm 97–Shortest Path.pdf:application/pdf},
}


@misc{networkit,
	title = {{NetworKit}},
	url = {https://networkit.github.io/index.html},
	publisher = {Humboldt-University of Berlin},
	author = {Angriman, Eugenio and van der Grinten, Alexander and Meyerhenke, Henning},
	month = apr,
	year = {2021},
	note = {Publication Title: NetworKit},
}

@unpublished{geisbergerthesis,
	address = {Universität Karlsruhe},
	type = {Student {Thesis}},
	title = {Better {Approximation} of {Betweenness} {Centrality}},
	url = {https://www.yumpu.com/en/document/view/16871703/better-approximation-of-betweenness-centrality-computer-science},
	abstract = {Centrality indices are used to classify a graph in important and unimportant vertices. A commonly used index isbetweenness centrality which is based on shortest paths. For large graphs it is almost impossible to calculate exact betweenness centrality in appropriate time. The best known algorithm today is based on solving n SSSPs and requires O(nm+n2log(n)) time. But in most cases, e.g. on a home computer, resources are limited. Current approximation algorithms extrapolate values by solving only k ≪ n SSSPs.Vertices near the source of a SSSP are often overestimated. We introduce improvements which take the distance to the source into account. Euclidean distance between approximation and exact values is reduced by factor 4 with same runtime. Or runtime is 16 times faster with same Euclidean distance in a standard example, the movie actor network. Other real-world networks show similar promising results.},
	author = {Geisberger, Robert},
	month = jan,
	year = {2008},
	annote = {Also at https://vdocuments.us/better-approximation-of-betweenness-2008-01-29-better-approximation-of-betweenness.html},
	file = {Geisberger - 2008 - Better Approximation of Betweenness Centrality.pdf:/home/iris/Zotero/storage/NE42B4FA/Geisberger - 2008 - Better Approximation of Betweenness Centrality.pdf:application/pdf},
}

@misc{erdoscode,
	title = {Dora {Erdos} {Homepage}},
	url = {https://cs-people.bu.edu/edori/code.html#Betweenness_centrality},
	urldate = {2021-04-22},
	file = {Dora Erdos Homepage:/home/iris/Zotero/storage/AMAT4VYJ/code.html:text/html},
}

@misc{kadabracode,
	title = {natema/kadabra},
	copyright = {Apache-2.0 License         ,                 Apache-2.0 License},
	url = {https://github.com/natema/kadabra},
	abstract = {KADABRA is an ADaptive Algorithm for Betweenness via Random Approximation},
	urldate = {2021-04-23},
	author = {natema},
	month = jul,
	year = {2020},
	note = {original-date: 2016-04-27T17:14:43Z},
}


@misc{bebecacode,
	title = {A {Benchmark} for {Betweenness} {Centrality} {Approximation} {Algorithms} on {Large} {Graphs}},
	url = {https://ecrc.github.io/BeBeCA/},
	journal = {BeBeCA A Benchmark for Betweenness Centrality Approximation Algorithms on Large Graphs},
	author = {AlGhamdi, Ziyad and Jamour, Fuad and Skiadopoulos, Spiros and Kalnis, Panos},
	year = {2017},
	keywords = {Approximation Algorithms, Betweenness Centrality, Experimental Evaluation, Social Networks},
	annote = {event-place: Chicago, IL, USA},
	file = {Full Text:/home/iris/Zotero/storage/GKKAJ9AH/AlGhamdi et al. - 2017 - A Benchmark for Betweenness Centrality Approximati.pdf:application/pdf},
}


@misc{metisparallel,
	title = {Partial {Parallelization} of {Graph} {Partitioning} {Algorithm} {METIS} {Term} {Project}},
	url = {/paper/Partial-Parallelization-of-Graph-Partitioning-METIS-Kasheff/a30132f8109026034a3261ae9f61ab808fa0e526},
	abstract = {The METIS graph partitioning algorithm has three stages. The first stage, coarsening, takes a large graph, with vertices {\textbar}V {\textbar} and edges {\textbar}E{\textbar}, and creates successively smaller graphs that are good representations of the original graph. The second stage partitions the small graph. The third stage, refinement, projects and refines the partition of the smaller graph onto the original graph. We present implementation details of a parallel coarsening algorithm that adds �({\textbar}V {\textbar}) parallelizable work to the original algorithm. we add �({\textbar}E{\textbar}) serial work for optimal performance that limits our program to being 2.72 times faster on 8 processors than 1 processor, and 1.22 times faster on 8 processors than the original algorithm. We present issues with parallelizing refinement along with suggestions towards dealing with the issues.},
	language = {en},
	urldate = {2021-04-25},
	author = {Kasheff, Zardosht},
	year = {2004},
	file = {Snapshot:/home/iris/Zotero/storage/KU5PU6DF/a30132f8109026034a3261ae9f61ab808fa0e526.html:text/html;Kasheff - 2004 - Partial Parallelization of Graph Partitioning Algo.pdf:/home/iris/Zotero/storage/YZ8SVVA3/Kasheff - 2004 - Partial Parallelization of Graph Partitioning Algo.pdf:application/pdf},
}


@article{fredman,
	title = {The pairing heap: {A} new form of self-adjusting heap},
	volume = {1},
	issn = {0178-4617, 1432-0541},
	shorttitle = {The pairing heap},
	url = {http://link.springer.com/10.1007/BF01840439},
	doi = {10.1007/BF01840439},
	language = {en},
	number = {1-4},
	urldate = {2021-04-25},
	journal = {Algorithmica},
	author = {Fredman, Michael L. and Sedgewick, Robert and Sleator, Daniel D. and Tarjan, Robert E.},
	month = nov,
	year = {1986},
	pages = {111--129},
	file = {Full Text:/home/iris/Zotero/storage/797DIMQ4/Fredman et al. - 1986 - The pairing heap A new form of self-adjusting hea.pdf:application/pdf},
}

@misc{schwarz,
	title = {Archive of Interesting Code - {FibonacciHeap}.java},
	url = {https://keithschwarz.com/interesting/code/?dir=fibonacci-heap},
	urldate = {2021-04-25},
	author = {Schwarz, Keith},
	file = {Archive of Interesting Code:/home/iris/Zotero/storage/3WK6WMQQ/code.html:text/html},
}
